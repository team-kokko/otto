{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\npersonal_access_token = user_secrets.get_secret(\"personal_access_token\")\n\n!rm -rf /kaggle/working/kaggle_otto\n!git clone -b covis-matrix https://$personal_access_token@github.com/coffeemountain/kaggle_otto.git\n    \nimport sys\nsys.path.append('/kaggle/working/kaggle_otto/src')\n\nfrom covis_matrix_generator import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-03T12:21:36.683833Z","iopub.execute_input":"2022-12-03T12:21:36.684210Z","iopub.status.idle":"2022-12-03T12:21:43.166166Z","shell.execute_reply.started":"2022-12-03T12:21:36.684128Z","shell.execute_reply":"2022-12-03T12:21:43.164826Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'kaggle_otto'...\nremote: Enumerating objects: 110, done.\u001b[K\nremote: Counting objects: 100% (110/110), done.\u001b[K\nremote: Compressing objects: 100% (89/89), done.\u001b[K\nremote: Total 110 (delta 51), reused 60 (delta 17), pack-reused 0\u001b[K\nReceiving objects: 100% (110/110), 63.61 KiB | 1.16 MiB/s, done.\nResolving deltas: 100% (51/51), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"USE_GPU = True\nweight_func_mixin = WeightFuncMixin()\ncovis_matrix_generator = CovisMatrixGenerator(weight_func_mixin, use_gpu=USE_GPU)","metadata":{"execution":{"iopub.status.busy":"2022-12-03T12:21:43.168172Z","iopub.execute_input":"2022-12-03T12:21:43.168767Z","iopub.status.idle":"2022-12-03T12:21:43.174117Z","shell.execute_reply.started":"2022-12-03T12:21:43.168723Z","shell.execute_reply":"2022-12-03T12:21:43.173073Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"files = glob.glob('../input/otto-chunk-data-inparquet-format/*_parquet/*')\n\nclick_config = Config(\n    target_types=[0, 1, 2], \n    weight_func='type_weight_1_6_3',\n    min_event_threshold=30,\n    max_sec_threshold=24 * 60 * 60,\n    save_topk=15,\n    output_dir='click'\n)\ncovis_matrix_generator.generate(click_config, files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buy_config = Config(\n    target_types=[1, 2],\n    weight_func='type_weight_1_1_1',\n    min_event_threshold=30,\n    max_sec_threshold=14 * 24 * 60 * 60,\n    save_topk=15,\n    output_dir='buy2buy'\n)\ncovis_matrix_generator.generate(buy_config, files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"click_timeweight_config = Config(\n    target_types=[0, 1, 2],\n    weight_func='time_weight_v1',\n    min_event_threshold=30,\n    max_sec_threshold=24 * 60 * 60,\n    save_topk=20,\n    output_dir='click_timeweight',\n)\ncovis_matrix_generator.generate(click_timeweight_config, files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del covis_matrix_generator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_labels = {'clicks':0, 'carts':1, 'orders':2}\n\ndef load_test():\n    dfs = []\n    for e, chunk_file in enumerate(glob.glob('../input/otto-chunk-data-inparquet-format/test_parquet/*')):\n        chunk = pd.read_parquet(chunk_file)\n        chunk.ts = (chunk.ts/1000).astype('int32')\n        chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n        dfs.append(chunk)\n    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n\ntest_df = load_test()\nprint('Test data has shape',test_df.shape)\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef pqt_to_dict(df):\n    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n\n# LOAD THREE CO-VISITATION MATRICES\npath_to_dir = '/kaggle/working/click'\ntop_20_buys = pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_0.pqt') )\nfor k in range(1,4): \n    top_20_buys.update( pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_{k}.pqt') ) )\n\npath_to_dir = '/kaggle/working/buy2buy'\ntop_20_buy2buy = pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_0.pqt') )\nfor k in range(1,4): \n    top_20_buy2buy.update( pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_{k}.pqt') ) )\n    \npath_to_dir = '/kaggle/working/click_timeweight'\ntop_20_clicks = pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_0.pqt') )\nfor k in range(1,4): \n    top_20_clicks.update( pqt_to_dict( pd.read_parquet(f'{path_to_dir}/part_{k}.pqt') ) )\n\n# TOP CLICKS AND ORDERS IN TEST\ntop_clicks = test_df.loc[test_df['type']=='clicks','aid'].value_counts().index.values[:20]\ntop_orders = test_df.loc[test_df['type']=='orders','aid'].value_counts().index.values[:20]\n\nprint('Here are size of our 3 co-visitation matrices:')\nprint( len( top_20_clicks ), len( top_20_buy2buy ), len( top_20_buys ) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#type_weight_multipliers = {'clicks': 1, 'carts': 6, 'orders': 3}\ntype_weight_multipliers = {0: 1, 1: 6, 2: 3}\n\ndef suggest_clicks(df):\n    # USER HISTORY AIDS AND TYPES\n    aids=df.aid.tolist()\n    types = df.type.tolist()\n    unique_aids = list(dict.fromkeys(aids[::-1] ))\n    # RERANK CANDIDATES USING WEIGHTS\n    if len(unique_aids)>=20:\n        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n        aids_temp = Counter() \n        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n        for aid,w,t in zip(aids,weights,types): \n            aids_temp[aid] += w * type_weight_multipliers[t]\n        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n        return sorted_aids\n    # USE \"CLICKS\" CO-VISITATION MATRIX\n    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n    # RERANK CANDIDATES\n    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids]    \n    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n    # USE TOP20 TEST CLICKS\n    return result + list(top_clicks)[:20-len(result)]\n\ndef suggest_buys(df):\n    # USER HISTORY AIDS AND TYPES\n    aids=df.aid.tolist()\n    types = df.type.tolist()\n    # UNIQUE AIDS AND UNIQUE BUYS\n    unique_aids = list(dict.fromkeys(aids[::-1] ))\n    df = df.loc[(df['type']==1)|(df['type']==2)]\n    unique_buys = list(dict.fromkeys( df.aid.tolist()[::-1] ))\n    # RERANK CANDIDATES USING WEIGHTS\n    if len(unique_aids)>=20:\n        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n        aids_temp = Counter() \n        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n        for aid,w,t in zip(aids,weights,types): \n            aids_temp[aid] += w * type_weight_multipliers[t]\n        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n        for aid in aids3: aids_temp[aid] += 0.1\n        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n        return sorted_aids\n    # USE \"CART ORDER\" CO-VISITATION MATRIX\n    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n    # RERANK CANDIDATES\n    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids] \n    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n    # USE TOP20 TEST ORDERS\n    return result + list(top_orders)[:20-len(result)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nimport pandas as pd, numpy as np\nfrom tqdm.notebook import tqdm\nimport os, sys, pickle, glob, gc\nfrom collections import Counter\nimport cudf, itertools\n\npred_df_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n    lambda x: suggest_clicks(x)\n)\n\npred_df_buys = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n    lambda x: suggest_buys(x)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\norders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\ncarts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\npred_df.columns = [\"session_type\", \"labels\"]\npred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\npred_df.to_csv(\"submission.csv\", index=False)\npred_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}